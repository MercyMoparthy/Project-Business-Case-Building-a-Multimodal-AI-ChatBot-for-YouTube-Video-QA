{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c9e2a5",
   "metadata": {},
   "source": [
    "## Model: distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67536a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone-client==3.0.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ab7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2607d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = \"youtube-transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ad5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8ff207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4e6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, top_k=10):\n",
    "    query_embedding = embedder.encode(query, show_progress_bar=False).tolist()\n",
    "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
    "    seen = set()\n",
    "    filtered = []\n",
    "    for match in results[\"matches\"]:\n",
    "        text = match[\"metadata\"].get(\"text\", \"\").strip().lower()\n",
    "        if text and text not in seen and len(text.split()) > 10:\n",
    "            seen.add(text)\n",
    "            filtered.append(match[\"metadata\"][\"text\"])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c047793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: set your query string here if not already defined\n",
    "query = \"What is ITSM in ServiceNow?\"\n",
    "\n",
    "query_keywords = query.lower().split()\n",
    "chunks = retrieve_chunks(query)\n",
    "chunks = [c for c in chunks if any(kw in c.lower() for kw in query_keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f04fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Retrieved Context Chunks:\n",
      "--------------------------------------------------\n",
      "the one used by servicenow to begin this process amelia paced json code shes copied from pingdum certain mandatory field must be configured at a minimum amelia finish up by configuring any additional field mapping needed based on what pingdum is prov\n",
      "--------------------------------------------------\n",
      "sure so a i said service operation work face which strongly recommend that you use service operation work face if you would like to use task intelligence for itsm because you would be able to use the complete power of both the product in service oper\n",
      "--------------------------------------------------\n",
      "available for service operation workspace so if you could repeat maybe what you said about word available sure so a i said service operation work face which strongly recommend that you use service operation work face if you would like to use task int\n",
      "--------------------------------------------------\n",
      "evans from the technical product and solution marketing team at servicenow were going to talk about servicenow it operation management specifically aiops and event management aiops or artificial intelligence for it operation is the practice of using \n",
      "--------------------------------------------------\n",
      "hi this is evans from the technical product and solution marketing team at servicenow today were going to talk about servicenow it operation management specifically aiops and event management aiops or artificial intelligence for it operation is the p\n",
      "--------------------------------------------------\n",
      "evans nicholson from technical marketing at servicenow to part two of the miniseries aipowered service operation starring servicenow itsm and itom at servicenow we understand the amount of data coming in and the complexity of hybrid cloud environment\n",
      "--------------------------------------------------\n",
      "love i would almost consider service operation to be part of my servicenow superhero origin story so i originally worked in operation thats where my background is wa always a bit kind of jealous about the serviceguys because they seemed to be able to\n",
      "--------------------------------------------------\n",
      "itam event management at the bottom you can see that the window ii server which is involved in the current payment gateway outage ha been producing a very high number of alert it easy to see the status of itam agent a well to make sure everything is \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chunks = retrieve_chunks(query)\n",
    "print(\"\\nüîç Retrieved Context Chunks:\\n\" + \"-\"*50)\n",
    "for c in chunks:\n",
    "    print(c[:250] + \"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce44821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunks(chunks, query):\n",
    "    combined = \" \".join(chunks)\n",
    "    prompt = (\n",
    "        f\"You are an expert in ServiceNow. Based on the content below, answer the question in a well-structured, professional way.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Context:\\n{combined}\\n\\n\"\n",
    "        f\"Answer (in 4-6 detailed sentences):\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=400)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594ec73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_from_summary(query, summary):\n",
    "    prompt = (\n",
    "        \"You are a professional ServiceNow consultant. \"\n",
    "        \"Based on the summary below, answer the question in a clear, complete, and professional tone. \"\n",
    "        \"Your answer should be at least 4‚Äì6 sentences and include key terminology or examples when applicable.\\n\\n\"\n",
    "        f\"Summary:\\n{summary}\\n\\n\"\n",
    "        f\"Question: {query}\\nAnswer:\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b464ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is ITSM in ServiceNow?\",\n",
    "    \"Explain CMDB relationships.\",\n",
    "    \"How does Incident Management work?\",\n",
    "    \"what are the AI capabilities in ServiceNow?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366e1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is ITSM in ServiceNow?\n",
      "A: event management\n",
      "================================================================================\n",
      "\n",
      "Q: Explain CMDB relationships.\n",
      "A: data fabric and the rapridb\n",
      "================================================================================\n",
      "\n",
      "Q: How does Incident Management work?\n",
      "A: the key is being proactive versus reactive and having the right supporting system to be able to achieve that in part one we saw how an issue with a company missioncritical internal ordering service wa causing a flood of new ticket in our service engineer queue we then showed how in parallel the operation engineer wa able to quickly determine probable root cause of the outage and trigger a service\n",
      "================================================================================\n",
      "\n",
      "Q: what are the AI capabilities in ServiceNow?\n",
      "A: event apps and ai agent to optimize business process resulting in more efficient operation and better employee productivity\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    try:\n",
    "        chunks = retrieve_chunks(query)\n",
    "        if not chunks:\n",
    "            print(f\"‚ö†Ô∏è No relevant context found for query: {query}\\n\")\n",
    "            continue\n",
    "\n",
    "        answer = summarize_chunks(chunks, query)\n",
    "        print(f\"Q: {query}\\nA: {answer}\\n{'='*80}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error for query '{query}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
