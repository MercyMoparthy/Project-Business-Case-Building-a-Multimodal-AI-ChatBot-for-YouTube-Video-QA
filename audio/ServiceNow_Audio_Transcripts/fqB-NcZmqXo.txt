 Hello everyone, welcome to another episode of the podcast. Today we're going to dive back into Agentec AI again and today I have another technology leader with me, Victor Chen, joins me. Victor, how are you? Doing well, thank you. Why don't you give a quick intro of yourself? Sure, so my name is Victor Chen, I am an outbound product manager at ServiceNow. I cover everything now assist with particularly focusing on our Agentec AI as well as our virtual agent. Awesome, just the right guy we need for this podcast. I ask this to every host, how do you use AI in your personal life or day to day things that you do? Any examples you have? Yeah, I used chatGPT since the very beginning and I recently used Microsoft Copa. I was trying to build I don't know, a power automate flow on SharePoint. Couldn't quite figure it out, so I just asked Copa, hey, I'm trying to do this, how do you do it? And it was pretty helpful in giving me the steps and I asked chatGPT too. So between those two tools, I was able to get this flow working. For a tool, I almost never use, I'm not familiar with this, so it's very helpful for that situation. That's nice. Yeah, I typically use, even when I creating this podcast, I use a couple of different tools and helps me out along with the tool I use here at Riverside, but also the chatGPT or even Copa, so kind of coming a couple of different things, which is very helpful. All right, awesome. Let's dive right in. It's a whole lot of talk about Agentec AI and its framework, but what does it look like in the context of ServiceNow platform? Yeah, so ServiceNow, we built our own Agentec AI framework on the Now platform. It is native to the Now platform. We didn't acquire companies, not a bolt-on. And it's additive to the innovations and the investments made to the platform over time, both by customers who have built on the platform, as well as us who've innovated onto it. Firstly, that means the ability to use the Now platform's data richness. So I'm talking about your user data, your CMDB, your knowledge, and all the external enterprise data that have people, folks and customers have tied into the Now platform via Integration Hub and soon also the tools available in workflow data fabric, so like zero copy data, etc. So all that data is what gives AI agents the context and the know how to fulfill its objectives. And then there's the workflows that are on the Now platform. So all our customers, they have workflows in ServiceNow, whether it's for IT, HR, CRM, and these workflows now also become tools for the AI agents to call upon and execute where need be. So you got data, you have workflows, you tie that all in in the Now platform that's secure and scalable, and you have a very powerful starting point or foundation to build and deploy AI agents for your work. Nice. Now you talked about a couple of things I want to dive deeper. One of them is data, of course. So what is the maturity of a customer looks like as they start adopting AI agents? Is there a data maturity also in there and aspect of that? Yeah, so like, you know, certainly that's a very pertinent question that a lot of our customers ask us like, are we ready for, you know, AI or genetic AI? And certainly, you know, customers, to your very first question to me, like, how do you use GenAI in your life? Like, customers need to be familiar with GenAI tools and workflows, both at ServiceNow and, you know, in the broader technology environment and be comfortable with large language models. Large language models, what they can do is perhaps some of their limitations as well, right? And that's been true since early GPT up to chat, GPT up to today, right? LLMs are constantly evolving, but there are always things you need to be aware of, etc. So the customer should be able to look at how they deploy, test and manage GenAI tools and enterprise always. This time goes for any AI tool. And so that's the kind of governance structure or the thought space an AI mature company should have us in, you know, ServiceNow has that. And like on the technical side, data drives performance of these agents and the LLMs that power them, right? So customers should have a strong data governance process when it comes to their knowledge base, catalogs, service catalog and tasks, etc. There's also, you mentioned workflow data fabric. So that allows our customers to get data from business applications, data lakes, and a variety of data sources, right? And that kind of data might not be present in ServiceNow already, but based on agile methods we have, our customers are able to grab the data and apply it to these agent take or AI use cases. And I think that is seamless for our customers, right? And then when we think about data governance, a lot of our customers have this question like, yeah, if the data is present in ServiceNow platform, we know that but when you are grabbing data from external sources, how does all landscape of governance and management looks like? Yeah, exactly. So you're exactly right. ServiceNow doesn't need to be the keeper of all your data. If you want to integrate your data with the Now platform, we allow that. If you want, again, zero copy and just connecting to your data lake or your enterprise applications without any of that data, leaving that application of the ecosystem, also fine. We are extensible and flexible to that point. When it comes to data governance, we talked a little bit about that earlier, but at a more like tactical level, it's making sure, for example, that your data is clean, that your knowledge base is up to date. So again, data cleanliness is always important, is always important regardless of the topic, right? And it's important like if customers are using AI agents to resolve incidents, for example, then there should be a good track record or a good historical record of incidents that have been resolved in the past with documentation like work notes and you know, you probably have comments or attachments in there. And that's how agents, AI agents can learn and generate resolution plans accordingly, right? So AI agents can generate a plan to resolve it and then act upon that plan. There's a flip side. You want to make sure that agents also don't access any data that you don't want them to have, you know, excluding or kind of managing out outdated knowledge articles, just one example, right? PII is another consideration. The good news, you know, the ServiceNow platform, we have sensitive data handling tools that allows you to mask sensitive data, allows you to manage that in a low co-format. So you're not starting from scratch. You know, when it comes to data governance, you know, we provide these tools and the platform itself provides that foundation to accelerate your deployment for AI tools confidently. We work with Data Constructions and other kind of the partners, right, to make sure like Huggingface and others to make sure that we are following the guardrails and guardrails that have been described by other constructions as well. Yeah, yeah, we have guardrails for LLMs. We have guardrails for data usage, privacy, security, you know, all the security and privacy policies that you're already familiar with on the Now platform, you know, they equally apply to our AI tools. Nice. Let's dive into the topic that I find very interesting. And that's for everyone out there's large language models has been, of course, activity every single day about whether it's OpenAI or DeepSeq or Claude. We just saw a couple of models come out versions over the weekend, the past couple of days as well. So how do we integrate these various models into building new use cases? And how do you use it? It looks like, but what is the landscape of managing these models for our customers looks like in the future as well? What do you what do you see that right now? Yeah, yeah, no, you're actually right. Like, you know, the past month has seen a proliferation of large language models by every company's trying to be the best model at the lowest cost. And that is good for service now. And that is good for our customers. Right. And, you know, so in our agentic framework, we use large, you know, just focus enough for a moment, we use large language models to orchestrate your team of agents, generating those plans of actions and then executing that action or series of actions, along with human and user feedback of what we like to call human on the loop. The other way that large language models are used is also used by the agent tools. So that could be, for example, if you want your agents to generate a knowledge article, search for information or run a custom now assist skill that you've built on the now platform, those also use large language models. And the good news for customers and for our customers is that we service now we are also constantly evaluating models to use in terms of performance and price. And when, when customers use now assist, they, they have the, they have two options, mainly they can use the LLMs that we host. And that means, you know, we host the LLMs, there's no customer data leaving the service now ecosystem or being used to train whatever model, right. And customers don't have to worry about double paying for tokens, right. We manage all that. The other way to use the models is just bring is bring your own model, right. So for those of you, for those customers who are familiar with our generative AI controller, we've had that principle for a long time. It's like, hey, you can use your own model to run gen AI workflows on the now platform. You can use your own models to run custom skills on now assist skill kit. And then looking forward, yes, you can use bring your own model, whether it's open AI, anthropic Gemini, what have you, right, to run agents or virtual agent or other now assist skills. So we are definitely, you know, in the spirit of extensibility and flexibility, we're going to open that up, you know, very, very soon. Nice. And a good thing about the industry is the training cost and the inference cost been just going down so significantly that customers don't really have to kind of worry about a lot of this. And with service now, giving them sort of a platform where they can apply different use cases together where they're distilled models or, you know, as you said, bring your own model, it just makes a very happy medium for our customers going forward. Yeah. And, you know, again, the model to your point is just a tool that layers on top of the platform that you have, right. It could be whatever LLM. And it's a platform that again provides the data, the workflow, the governance tools, the security, all that so that we abstract that complexity away as much as possible. So our customers can get time to value as quickly as possible with these AI tools, with AI agents. Yeah. It's an interesting, actually it's called Jevons Paradox, if you have heard about it. It's an interesting way of, as the technology goes, much cheaper, the kind of the adoption of that technology or use cases actually accelerate. So for our customers and us as well as the cost of models come down, it just means you're going to have more adoption and easily, you know, you can do more things with it. So that's amazing. And that actually leads me to this. One other question is, as these models proliferate and technology becomes available in our platform, which I call our platform is very extensible to so many use cases, what are some of the most significant outcomes that our customers can expect? Yeah, no, that's a great question. You know, what I tell folks is the big unlock for AI agents is productivity at scale. AI agents never rest. They operate 24 seven. They're constantly observing, receiving issues and taking actions on behalf of whether, you know, it's their end user employees, whether it's perhaps a service desk or, you know, a team of fulfillers. And this enables customers to raise expectations on fulfilling the KPIs and the objectives that your business has, whether that's that's issue deflection, or whether that's time, you know, mean time to resolution, ESAT, CSAT, etc. Right. Like every business has these for just for example, for HR, employee satisfaction, HR onboarding, for example, and for CRM, right, making sure your customers get the resolution they need, make sure, make sure your customers are satisfied and happy and come back to you for more, right. AI agents will touch every corner of the business and their ability to automate and build and their ability to achieve efficiencies. So it's, it's a very exciting space, really, you know, dare say your imagination is really the limit and what AI agents can achieve and what they can unlock for, for, for those who are using them. Yeah, that's well said. Just like our CEO says, well, right, as you said, imagination is your limit. And then also, I like what he says about that our AI agents in service to humans, right? So that's, that's your point as well earlier. As we wrap up, I know it's a lot happening in this space. And we're going to have a lot of exciting developments in the coming weeks. How can our customers keep on top of these developments and you know, stay in touch with whatever is next just coming on the agentic framework. Yeah, so, you know, this is where I, this is where I plug all our service now content, right. So, you know, we're going to be making a lot of exciting announcements for when we release AA agents to general availability with our Yokohama release on March 12. So definitely stay tuned for that. Yeah, stay tuned on our website. And if you go to servicenow.com, you see we have a lot of information and a lot of things to share, content to share there on AA agents, which there's always going to be the opportunity to get more in depth knowledge and to join discussions with your peers on community. If you're a customer on partner portal, if you're a partner, right. And you know, wherever you get your service now kind of feed Twitter, LinkedIn, or I guess I should call X, X LinkedIn, etc. Right. And of course, I'd be remiss if our customers, if I don't mention our customer should come to knowledge, right, our knowledge conference in May. And there we're going to show off the future of agentic AI at ServiceNow. You get the opportunity to hear from our product teams. I'll be there. And you'll be able to get a hands on look on how AI agents will transform businesses and expectations for what I can do for you and what I can do on the now platform. So those are the places I would definitely take a look at. So, you know, please when if you have the opportunity, register for knowledge, visit a website. Awesome. That's a great plug. Victor, it was a pleasure to have you on the podcast. We'll get you back here as we get more development going. Thanks for listening, everyone. Bye for now. Thank you.