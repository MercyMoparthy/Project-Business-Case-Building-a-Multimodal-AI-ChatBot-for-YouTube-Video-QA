{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b681f",
   "metadata": {},
   "source": [
    "## LangChain Agent + Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20302209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from langchain.tools import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n",
    "def transcribe_audio(file_path):\n",
    "    print(\"DEBUG: file_path =\", file_path, type(file_path))\n",
    "    result = whisper_model.transcribe(file_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557077c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_qa(query):\n",
    "    return rag_pipeline(query)\n",
    "qa_tool = Tool(\n",
    "    name=\"YouTubeQA\",\n",
    "    func=rag_qa,\n",
    "    description=\"Answer questions about YouTube videos using RAG.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mercy\\AppData\\Local\\Temp\\ipykernel_26244\\3905989239.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")  # or use your preferred model\n",
      "C:\\Users\\Mercy\\AppData\\Local\\Temp\\ipykernel_26244\\3905989239.py:5: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "tools = [qa_tool]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7885\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mServiceNow is a cloud-based platform that provides a wide range of IT services and automates various business processes. It is primarily used for IT service management (ITSM), but it also offers modules for customer service, HR, security operations, and more. ServiceNow helps organizations streamline their workflows, improve efficiency, and enhance their overall service delivery.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCMDB stands for Configuration Management Database in ServiceNow. It is a centralized database that stores information about all the configuration items in an organization's IT infrastructure. This includes details about hardware, software, network devices, and other components. The CMDB helps organizations manage and track their IT assets, configurations, and relationships between different components.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def process_audio_with_agent(audio_file):\n",
    "    text_query = transcribe_audio(audio_file)\n",
    "    answer = agent.run(input=text_query)\n",
    "    return f\"Q: {text_query}\\n\\nA: {answer}\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=process_audio_with_agent,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record or Upload Audio\"),\n",
    "    outputs=gr.Textbox(label=\"Q & A\", lines=6),\n",
    "    title=\"YouTube RAG Agent: Ask by Voice!\",\n",
    "    description=\"The answer will appear below your transcribed question.\"\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
