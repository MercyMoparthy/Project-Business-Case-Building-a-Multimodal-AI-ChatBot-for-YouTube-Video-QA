{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b681f",
   "metadata": {},
   "source": [
    "## LangChain Agent + Speech Recognition\n",
    "* **Model Used:** Whisper to transcribe Audio files\n",
    "* **LLM Model:** gpt-3.5-turbo\n",
    "* **Tool used for Deployment:** Gradio\n",
    "* **Chatbot:** ServiceNow QA Agent - Text and Audio support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfca81d",
   "metadata": {},
   "source": [
    "## Step1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20302209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from langchain.tools import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3105a",
   "metadata": {},
   "source": [
    "## Step2: Whisper Model for Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8664ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n",
    "def transcribe_audio(file_path):\n",
    "    print(\"DEBUG: file_path =\", file_path, type(file_path))\n",
    "    result = whisper_model.transcribe(file_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e6d71",
   "metadata": {},
   "source": [
    "## Step3: RAG QA Tool Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557077c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_qa(query):\n",
    "    return rag_pipeline(query) # type: ignore\n",
    "qa_tool = Tool(\n",
    "    name=\"YouTubeQA\",\n",
    "    func=rag_qa,\n",
    "    description=\"Answer questions about YouTube videos using RAG.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfa48f",
   "metadata": {},
   "source": [
    "## Step4: LLM Model with Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d107c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mercy\\AppData\\Local\\Temp\\ipykernel_25472\\3760734133.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\Mercy\\AppData\\Local\\Temp\\ipykernel_25472\\3760734133.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "tools = [qa_tool]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25a83b",
   "metadata": {},
   "source": [
    "## Step5: Deploy Interface for Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db2ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_audio_with_agent(audio_file):\n",
    "    text_query = transcribe_audio(audio_file)\n",
    "    answer = agent.run(input=text_query)\n",
    "    return f\"Q: {text_query}\\n\\nA: {answer}\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=process_audio_with_agent,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Record or Upload Audio\"),\n",
    "    outputs=gr.Textbox(label=\"Q & A\", lines=6),\n",
    "    title=\"ServiceNow QA Assistant: Ask by Voice!\",\n",
    "    description=\"The answer will appear below your transcribed question.\"\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46c4e3",
   "metadata": {},
   "source": [
    "## Step6: Deploy Interface for Audio and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c68c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mercy\\AppData\\Local\\Temp\\ipykernel_25472\\3495208296.py:18: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://9bce2684e90b149d41.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9bce2684e90b149d41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: file_path = C:\\Users\\Mercy\\AppData\\Local\\Temp\\gradio\\78be28e7dc6119d1c446aefcfb9d43aba51d7126525f37211bfd2c3f5407d710\\Question 1.m4a <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What are the AI functionalities available in ServiceNow?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `YouTubeQA` with `AI functionalities in ServiceNow`\n",
      "\n",
      "\n",
      "\u001b[0mDEBUG: file_path = C:\\Users\\Mercy\\AppData\\Local\\Temp\\gradio\\78be28e7dc6119d1c446aefcfb9d43aba51d7126525f37211bfd2c3f5407d710\\Question 1.m4a <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What are the AI functionalities available in ServiceNow?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `YouTubeQA` with `AI functionalities in ServiceNow`\n",
      "\n",
      "\n",
      "\u001b[0mDEBUG: file_path = C:\\Users\\Mercy\\AppData\\Local\\Temp\\gradio\\320ad5ef4328994efffd8723bc1e9ee9b45a6ee431a9e831cdd6f0eab076bc97\\Question 2.mp3 <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is CMDB in service now?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCMDB stands for Configuration Management Database in ServiceNow. It is a centralized repository that stores information about all the configuration items (CIs) in an organization's IT infrastructure. This includes hardware, software, applications, and other components that are essential for delivering IT services. The CMDB in ServiceNow helps organizations track and manage their IT assets, relationships between assets, and the impact of changes on the IT environment. It plays a crucial role in IT service management and helps organizations improve service delivery, reduce risks, and enhance decision-making.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def process_query(text_query, audio_file, history):\n",
    "    if audio_file is not None:\n",
    "        text_query = transcribe_audio(audio_file)\n",
    "        question = text_query\n",
    "    elif text_query and text_query.strip():\n",
    "        question = text_query.strip()\n",
    "    else:\n",
    "        return history + [(\"User\", \"Please enter a question or upload audio.\")]\n",
    "    answer = agent.run(input=question)\n",
    "    history = history + [(f\"User: {question}\", f\"Agent: {answer}\")]\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"<h1 style='text-align: center;'>ServiceNow QA Agent</h1>\")\n",
    "    gr.Markdown(\"<center>Type or record your question below. The bot will provide you answer</center>\")\n",
    "    chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(label=\"Type Your Question\", lines=2)\n",
    "        audio_input = gr.Audio(type=\"filepath\", label=\"Or Record/Upload Audio\")\n",
    "    submit = gr.Button(\"Submit\")\n",
    "    #clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    state = gr.State([])  # to hold chat history\n",
    "\n",
    "    submit.click(\n",
    "        process_query,\n",
    "        inputs=[text_input, audio_input, state],\n",
    "        outputs=chatbot\n",
    "    ).then(\n",
    "        lambda history: history,  # update state with latest history\n",
    "        inputs=chatbot,\n",
    "        outputs=state\n",
    "    )\n",
    "    #clear.click(\n",
    "        #lambda: [],\n",
    "        #None,\n",
    "        #[chatbot, state]\n",
    "    #)\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f70cc5",
   "metadata": {},
   "source": [
    "## Note: to upload Audio file - format should be mp3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
