{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe8b7a6",
   "metadata": {},
   "source": [
    "## PROJECT: Business Case - Building a Multimodel AI Chatbot for Youtube Videos\n",
    "** Preparing Data **\n",
    "* Creating CSV file with Youtube video links - 22 records\n",
    "* Extracting Metadata from Youtube using CSV file\n",
    "* Generating Audio files from Youtube using Metadata\n",
    "* Transcripting Audio Files using \"WHISPER\" Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfe235",
   "metadata": {},
   "source": [
    "## Step 1: Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad61a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in c:\\users\\mercy\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (2025.6.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yt-dlp\n",
    "%pip install pandas numpy --quiet\n",
    "%pip install openai-whisper --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad51fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yt_dlp\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a87ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg-7.1.1-essentials_build\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a490542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number                                 Youtube_link  \\\n",
      "0       1  https://www.youtube.com/watch?v=tOaMRG8DX3U   \n",
      "1       2  https://www.youtube.com/watch?v=vteLoWpNw8Q   \n",
      "2       3  https://www.youtube.com/watch?v=7WJ6lmxa1WQ   \n",
      "3       4  https://www.youtube.com/watch?v=fqB-NcZmqXo   \n",
      "4       5  https://www.youtube.com/watch?v=ZYJqkxGrNiI   \n",
      "\n",
      "                                             Subject  \n",
      "0  An AI Agent that knows everything about your P...  \n",
      "1          What Is Agentic AI and Why Should I Care?  \n",
      "2                     Agentic AI workflows for AIOps  \n",
      "3  ServiceNow's agentic AI framework explained: W...  \n",
      "4  AI and Business Agility: Enhancing Human Intel...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/SNOW_YT_Videos.csv\", sep=\";\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a037a8",
   "metadata": {},
   "source": [
    "## Convert Videos to MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b188e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] tOaMRG8DX3U: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] tOaMRG8DX3U: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] ThW6lPyYgYk: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] ThW6lPyYgYk: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube:tab] YouTube said: INFO - 2 unavailable videos are hidden\n",
      "ERROR: [youtube] VFGAvNxaK4Q: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"Data\", exist_ok=True)\n",
    "\n",
    "def get_metadata_yt_dlp(video_url):\n",
    "    ydl_opts = {'quiet': True, 'skip_download': True}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "            return {\n",
    "                \"title\": info.get(\"title\"),\n",
    "                \"channel\": info.get(\"uploader\"),\n",
    "                \"description\": info.get(\"description\", \"\")[:200],\n",
    "                \"length\": info.get(\"duration\"),\n",
    "                \"publish_date\": info.get(\"upload_date\"),\n",
    "                \"views\": info.get(\"view_count\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "metadata_list = [get_metadata_yt_dlp(link) for link in df[\"Youtube_link\"]]\n",
    "metadata_df = pd.DataFrame(metadata_list)\n",
    "final_df = pd.concat([df, metadata_df], axis=1)\n",
    "final_df.to_csv(\"../Data/ServiceNow_Youtube_Metadata_Clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ecda5",
   "metadata": {},
   "source": [
    "## Transcription with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a226dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/ServiceNow_Youtube_Metadata_Clean.csv\", sep=\";\")\n",
    "model = whisper.load_model(\"base\")\n",
    "os.makedirs(\"../audio/audio_files\", exist_ok=True)\n",
    "\n",
    "def download_audio(url, video_id):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': f'audio_files/{video_id}.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': True\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        return f'audio_files/{video_id}.mp3'\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55405f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcripts already exist. Skipping transcription step.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "\n",
    "output_path = \"../data/video_metadata_with_transcripts.csv\"\n",
    "\n",
    "# Check if the file exists and has non-empty transcripts\n",
    "if os.path.exists(output_path):\n",
    "    existing_df = pd.read_csv(output_path)\n",
    "    if \"transcript\" in existing_df.columns and not existing_df[\"transcript\"].isnull().all():\n",
    "        print(\"‚úÖ Transcripts already exist. Skipping transcription step.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Transcripts missing or empty. Running transcription...\")\n",
    "        run_transcription = True\n",
    "else:\n",
    "    print(\"üìÇ File not found. Running transcription...\")\n",
    "    run_transcription = True\n",
    "\n",
    "if 'run_transcription' in locals():\n",
    "    transcripts = []\n",
    "\n",
    "    for idx, row in final_df.iterrows():\n",
    "        url = row['Youtube_link']\n",
    "        video_id = url.split(\"v=\")[-1]\n",
    "        print(f\"üîä Processing video {idx+1}: {url}\")\n",
    "\n",
    "        audio_path = download_audio(url, video_id)\n",
    "        if audio_path and os.path.exists(audio_path):\n",
    "            try:\n",
    "                result = model.transcribe(audio_path)\n",
    "                transcripts.append(result['text'])\n",
    "            except Exception as e:\n",
    "                transcripts.append(f\"Error during transcription: {str(e)}\")\n",
    "        else:\n",
    "            transcripts.append(\"Error: Audio download failed or video may be protected\")\n",
    "\n",
    "    final_df[\"transcript\"] = transcripts\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(\"‚úÖ Transcripts saved to:\", output_path)\n",
    "\n",
    "#print(\"‚úÖ Transcripts saved to video_metadata_with_transcripts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
